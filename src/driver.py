# -*- coding: utf-8 -*-
"""analysis_w_paper_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EZTRUg9Hg-sofoig8vkJjhp_09YQnn_G
"""
#!pip install optuna
#import index_maker
import util
import argparse
import yaml
import importlib
#import optuna
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import tensorflow as tf
import random
from sklearn.ensemble import RandomForestRegressor
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Activation, Dropout, Flatten, Input, Dense, concatenate 
from sklearn.metrics import accuracy_score, precision_score, recall_score, r2_score, mean_squared_error
from tensorflow.keras.models import Model, Sequential, load_model
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import preprocessing
import dataloader
from preprocessing import preprocessor
from dataloader import dataLoader
import sys
import os
import os.path
import csv
#import ensemRegressor
#import optunatransformator1
#import IPT
#import source_only
import mpi4py
#from IPT import IPT
#from source_only import source_only
from mpi4py import MPI
#np.random.seed(1)  
#tf.random.set_seed(2)
#import optunannPOD
import re    
if __name__ == "__main__":
  comm = MPI.COMM_WORLD
  rank = comm.Get_rank()
  print(f"Rank is {rank}")
  #path_to_module = '/content/drive/MyDrive/'
  np.random.seed(1)  
  tf.random.set_seed(2)
  
  os.chdir("../../")
  parser = argparse.ArgumentParser()
  parser.add_argument('target_app', type=str,  help="name of the target domain")
  parser.add_argument('use_case', type=str,  help="which do want to fo from train_only, source_only, transfer_learning, random_forrest, k_regressor, IPT and stacked_model")
  parser.add_argument('yaml', type=str,  help="what will be the yaml file")
  args = parser.parse_args()
  with open(os.getcwd()+args.yaml, "r") as f:
    global_config= yaml.load(f, Loader=yaml.FullLoader)
  test_samples = global_config['test_samples']
  use_case_specific_config = global_config[args.use_case]
  loader = dataLoader(os.getcwd()+global_config["src_path"], os.getcwd()+global_config["tar_path"])
  loader.loadData()
  src_x, src_y, tar_x, tar_y = loader.getXY("", "",global_config["target_label"])
  if args.use_case == "target_only":
      src_x, src_y, tar_x, tar_y = loader.src_tx, loader.src_y, loader.tar_tx, loader.tar_y
  print("Src x shape before preprocessing")
  print(src_x.shape)
  print(src_x)
  print("Tar_x shape before preprocessing")
  print(tar_x.shape)
  print("Src y before preprocessing")
  print(src_y)
  #print(f"{tar_x.shape}, {tar_y.shape}")
  p = preprocessor(src_x, src_y, tar_x, tar_y, 0)
  print("Src y after preprocessing")
  print(src_y)
  p.setTrainStorage(global_config["stdy"], global_config["storageN"])
  p.setUseCase(args.use_case)
  p.setNumOfTrials(global_config["tuning_trials"])
  p.setTrialEpochs(global_config["tuning_epochs"])
  p.setTargetColumn(global_config["target_label"])
  src_tx, src_ty = loader.getSrcXY()
  p.setSrcDFXY(src_tx, src_ty)
  tar_tx, tar_ty = loader.getTarXY()
  p.setTarDFXY(tar_tx, tar_ty)
  p.preprocess()
  tar_x_scaled, tar_y_scaled = p.getTargetScaled()
  X_train, y_train, src_train, src_y_train, src_val, src_y_val, X_test, y_test = p.train_test_val( global_config["test_split"], global_config["val_split"], global_config["rand_state"], global_config["rand_state2"])
  try:
    with tf.device('/gpu:0'):
      module_name, func_name = use_case_specific_config["module_name"], use_case_specific_config["class_name"]
      module = importlib.import_module(module_name)
      func = getattr(module, func_name)
      obj = func(use_case_specific_config["init_arg"])
      obj(os.getcwd()+args.yaml, os.getcwd()+global_config["result_path"], test_samples, args.target_app, global_config["num_of_frozen_layers"], loader, p, X_train, y_train, rank)
  except RuntimeError as e:
    print(e)
